digraph {
	graph [size="31.799999999999997,31.799999999999997"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2533319736480 [label="
 (1, 2)" fillcolor=darkolivegreen1]
	2533828925312 [label=AddmmBackward0]
	2533836040144 -> 2533828925312
	2533319730160 [label="fc.bias
 (2)" fillcolor=lightblue]
	2533319730160 -> 2533836040144
	2533836040144 [label=AccumulateGrad]
	2533836040240 -> 2533828925312
	2533836040240 [label=MulBackward0]
	2533806445696 -> 2533836040240
	2533806445696 [label=ViewBackward0]
	2533836039952 -> 2533806445696
	2533836039952 [label=SqueezeBackward1]
	2533813933808 -> 2533836039952
	2533813933808 [label=MeanBackward1]
	2533836040432 -> 2533813933808
	2533836040432 [label=UnsqueezeBackward0]
	2533836040528 -> 2533836040432
	2533836040528 [label=ReluBackward0]
	2533836040624 -> 2533836040528
	2533836040624 [label=AddBackward0]
	2533836040720 -> 2533836040624
	2533836040720 [label=NativeBatchNormBackward0]
	2533832889760 -> 2533836040720
	2533832889760 [label=ConvolutionBackward0]
	2533813933760 -> 2533832889760
	2533813933760 [label=ReluBackward0]
	2533836041104 -> 2533813933760
	2533836041104 [label=NativeBatchNormBackward0]
	2533836041200 -> 2533836041104
	2533836041200 [label=ConvolutionBackward0]
	2533836041392 -> 2533836041200
	2533836041392 [label=ReluBackward0]
	2533836041536 -> 2533836041392
	2533836041536 [label=AddBackward0]
	2533836041632 -> 2533836041536
	2533836041632 [label=NativeBatchNormBackward0]
	2533836041776 -> 2533836041632
	2533836041776 [label=ConvolutionBackward0]
	2533836041968 -> 2533836041776
	2533836041968 [label=ReluBackward0]
	2533836042112 -> 2533836041968
	2533836042112 [label=NativeBatchNormBackward0]
	2533836042208 -> 2533836042112
	2533836042208 [label=ConvolutionBackward0]
	2533836042400 -> 2533836042208
	2533836042400 [label=ReluBackward0]
	2533836042544 -> 2533836042400
	2533836042544 [label=AddBackward0]
	2533836042640 -> 2533836042544
	2533836042640 [label=NativeBatchNormBackward0]
	2533836042784 -> 2533836042640
	2533836042784 [label=ConvolutionBackward0]
	2533836042976 -> 2533836042784
	2533836042976 [label=ReluBackward0]
	2533836043120 -> 2533836042976
	2533836043120 [label=NativeBatchNormBackward0]
	2533836043216 -> 2533836043120
	2533836043216 [label=ConvolutionBackward0]
	2533836043408 -> 2533836043216
	2533836043408 [label=SqueezeBackward1]
	2533836043552 -> 2533836043408
	2533836043552 [label=AvgPool2DBackward0]
	2533836043648 -> 2533836043552
	2533836043648 [label=UnsqueezeBackward0]
	2533836043744 -> 2533836043648
	2533836043744 [label=ReluBackward0]
	2533836043792 -> 2533836043744
	2533836043792 [label=NativeBatchNormBackward0]
	2533836043936 -> 2533836043792
	2533836043936 [label=ConvolutionBackward0]
	2533836044224 -> 2533836043936
	2533319682128 [label="conv1.weight
 (2, 1, 3)" fillcolor=lightblue]
	2533319682128 -> 2533836044224
	2533836044224 [label=AccumulateGrad]
	2533836043888 -> 2533836043792
	2533319682288 [label="bn1.weight
 (2)" fillcolor=lightblue]
	2533319682288 -> 2533836043888
	2533836043888 [label=AccumulateGrad]
	2533836044032 -> 2533836043792
	2533319682048 [label="bn1.bias
 (2)" fillcolor=lightblue]
	2533319682048 -> 2533836044032
	2533836044032 [label=AccumulateGrad]
	2533836043360 -> 2533836043216
	2533319687168 [label="layer1.0.conv1.weight
 (2, 2, 3)" fillcolor=lightblue]
	2533319687168 -> 2533836043360
	2533836043360 [label=AccumulateGrad]
	2533836043168 -> 2533836043120
	2533319687088 [label="layer1.0.bn1.weight
 (2)" fillcolor=lightblue]
	2533319687088 -> 2533836043168
	2533836043168 [label=AccumulateGrad]
	2533836043024 -> 2533836043120
	2533319675728 [label="layer1.0.bn1.bias
 (2)" fillcolor=lightblue]
	2533319675728 -> 2533836043024
	2533836043024 [label=AccumulateGrad]
	2533836042928 -> 2533836042784
	2533319677168 [label="layer1.0.conv2.weight
 (2, 2, 3)" fillcolor=lightblue]
	2533319677168 -> 2533836042928
	2533836042928 [label=AccumulateGrad]
	2533836042736 -> 2533836042640
	2533319677088 [label="layer1.0.bn2.weight
 (2)" fillcolor=lightblue]
	2533319677088 -> 2533836042736
	2533836042736 [label=AccumulateGrad]
	2533836042688 -> 2533836042640
	2533319687968 [label="layer1.0.bn2.bias
 (2)" fillcolor=lightblue]
	2533319687968 -> 2533836042688
	2533836042688 [label=AccumulateGrad]
	2533836042592 -> 2533836042544
	2533836042592 [label=NativeBatchNormBackward0]
	2533836043264 -> 2533836042592
	2533836043264 [label=ConvolutionBackward0]
	2533836043408 -> 2533836043264
	2533836043312 -> 2533836043264
	2533319688048 [label="layer1.0.downsample.0.weight
 (2, 2, 1)" fillcolor=lightblue]
	2533319688048 -> 2533836043312
	2533836043312 [label=AccumulateGrad]
	2533836043696 -> 2533836042592
	2533319687568 [label="layer1.0.downsample.1.weight
 (2)" fillcolor=lightblue]
	2533319687568 -> 2533836043696
	2533836043696 [label=AccumulateGrad]
	2533836042832 -> 2533836042592
	2533319687488 [label="layer1.0.downsample.1.bias
 (2)" fillcolor=lightblue]
	2533319687488 -> 2533836042832
	2533836042832 [label=AccumulateGrad]
	2533836042352 -> 2533836042208
	2533319724960 [label="layer2.0.conv1.weight
 (4, 2, 3)" fillcolor=lightblue]
	2533319724960 -> 2533836042352
	2533836042352 [label=AccumulateGrad]
	2533836042160 -> 2533836042112
	2533319724880 [label="layer2.0.bn1.weight
 (4)" fillcolor=lightblue]
	2533319724880 -> 2533836042160
	2533836042160 [label=AccumulateGrad]
	2533836042016 -> 2533836042112
	2533319731360 [label="layer2.0.bn1.bias
 (4)" fillcolor=lightblue]
	2533319731360 -> 2533836042016
	2533836042016 [label=AccumulateGrad]
	2533836041920 -> 2533836041776
	2533319731120 [label="layer2.0.conv2.weight
 (4, 4, 3)" fillcolor=lightblue]
	2533319731120 -> 2533836041920
	2533836041920 [label=AccumulateGrad]
	2533836041728 -> 2533836041632
	2533319724640 [label="layer2.0.bn2.weight
 (4)" fillcolor=lightblue]
	2533319724640 -> 2533836041728
	2533836041728 [label=AccumulateGrad]
	2533836041680 -> 2533836041632
	2533319724560 [label="layer2.0.bn2.bias
 (4)" fillcolor=lightblue]
	2533319724560 -> 2533836041680
	2533836041680 [label=AccumulateGrad]
	2533836041584 -> 2533836041536
	2533836041584 [label=NativeBatchNormBackward0]
	2533836042256 -> 2533836041584
	2533836042256 [label=ConvolutionBackward0]
	2533836042400 -> 2533836042256
	2533836042304 -> 2533836042256
	2533319731680 [label="layer2.0.downsample.0.weight
 (4, 2, 1)" fillcolor=lightblue]
	2533319731680 -> 2533836042304
	2533836042304 [label=AccumulateGrad]
	2533836042880 -> 2533836041584
	2533319731600 [label="layer2.0.downsample.1.weight
 (4)" fillcolor=lightblue]
	2533319731600 -> 2533836042880
	2533836042880 [label=AccumulateGrad]
	2533836041824 -> 2533836041584
	2533319725040 [label="layer2.0.downsample.1.bias
 (4)" fillcolor=lightblue]
	2533319725040 -> 2533836041824
	2533836041824 [label=AccumulateGrad]
	2533836041344 -> 2533836041200
	2533319724080 [label="layer3.0.conv1.weight
 (8, 4, 3)" fillcolor=lightblue]
	2533319724080 -> 2533836041344
	2533836041344 [label=AccumulateGrad]
	2533836041152 -> 2533836041104
	2533319730400 [label="layer3.0.bn1.weight
 (8)" fillcolor=lightblue]
	2533319730400 -> 2533836041152
	2533836041152 [label=AccumulateGrad]
	2533836041008 -> 2533836041104
	2533319730320 [label="layer3.0.bn1.bias
 (8)" fillcolor=lightblue]
	2533319730320 -> 2533836041008
	2533836041008 [label=AccumulateGrad]
	2533836040960 -> 2533832889760
	2533319723760 [label="layer3.0.conv2.weight
 (8, 8, 3)" fillcolor=lightblue]
	2533319723760 -> 2533836040960
	2533836040960 [label=AccumulateGrad]
	2533836040864 -> 2533836040720
	2533319730560 [label="layer3.0.bn2.weight
 (8)" fillcolor=lightblue]
	2533319730560 -> 2533836040864
	2533836040864 [label=AccumulateGrad]
	2533836040816 -> 2533836040720
	2533319730480 [label="layer3.0.bn2.bias
 (8)" fillcolor=lightblue]
	2533319730480 -> 2533836040816
	2533836040816 [label=AccumulateGrad]
	2533836040672 -> 2533836040624
	2533836040672 [label=NativeBatchNormBackward0]
	2533836041248 -> 2533836040672
	2533836041248 [label=ConvolutionBackward0]
	2533836041392 -> 2533836041248
	2533836041296 -> 2533836041248
	2533319730880 [label="layer3.0.downsample.0.weight
 (8, 4, 1)" fillcolor=lightblue]
	2533319730880 -> 2533836041296
	2533836041296 [label=AccumulateGrad]
	2533836041872 -> 2533836040672
	2533319730800 [label="layer3.0.downsample.1.weight
 (8)" fillcolor=lightblue]
	2533319730800 -> 2533836041872
	2533836041872 [label=AccumulateGrad]
	2533836040768 -> 2533836040672
	2533319724320 [label="layer3.0.downsample.1.bias
 (8)" fillcolor=lightblue]
	2533319724320 -> 2533836040768
	2533836040768 [label=AccumulateGrad]
	2533836040192 -> 2533828925312
	2533836040192 [label=TBackward0]
	2533827898736 -> 2533836040192
	2533319730240 [label="fc.weight
 (2, 8)" fillcolor=lightblue]
	2533319730240 -> 2533827898736
	2533827898736 [label=AccumulateGrad]
	2533828925312 -> 2533319736480
}
