digraph {
	graph [size="31.799999999999997,31.799999999999997"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2022041999696 [label="
 (1, 2)" fillcolor=darkolivegreen1]
	2022050282080 [label=AddmmBackward0]
	2022049096864 -> 2022050282080
	2021540216128 [label="fc.bias
 (2)" fillcolor=lightblue]
	2021540216128 -> 2022049096864
	2022049096864 [label=AccumulateGrad]
	2022045452944 -> 2022050282080
	2022045452944 [label=MulBackward0]
	2022049961760 -> 2022045452944
	2022049961760 [label=ViewBackward0]
	2022054421712 -> 2022049961760
	2022054421712 [label=SqueezeBackward1]
	2022054421808 -> 2022054421712
	2022054421808 [label=MeanBackward1]
	2022054421904 -> 2022054421808
	2022054421904 [label=UnsqueezeBackward0]
	2022054422000 -> 2022054421904
	2022054422000 [label=ReluBackward0]
	2022054422096 -> 2022054422000
	2022054422096 [label=AddBackward0]
	2022054422192 -> 2022054422096
	2022054422192 [label=NativeBatchNormBackward0]
	2022054422336 -> 2022054422192
	2022054422336 [label=ConvolutionBackward0]
	2022054422528 -> 2022054422336
	2022054422528 [label=ReluBackward0]
	2022054422672 -> 2022054422528
	2022054422672 [label=NativeBatchNormBackward0]
	2022054422768 -> 2022054422672
	2022054422768 [label=ConvolutionBackward0]
	2022054422960 -> 2022054422768
	2022054422960 [label=ReluBackward0]
	2022054423104 -> 2022054422960
	2022054423104 [label=AddBackward0]
	2022054423200 -> 2022054423104
	2022054423200 [label=NativeBatchNormBackward0]
	2022054423344 -> 2022054423200
	2022054423344 [label=ConvolutionBackward0]
	2022054423536 -> 2022054423344
	2022054423536 [label=ReluBackward0]
	2022054423680 -> 2022054423536
	2022054423680 [label=NativeBatchNormBackward0]
	2022054423776 -> 2022054423680
	2022054423776 [label=ConvolutionBackward0]
	2022054423968 -> 2022054423776
	2022054423968 [label=ReluBackward0]
	2022054424112 -> 2022054423968
	2022054424112 [label=AddBackward0]
	2022054424208 -> 2022054424112
	2022054424208 [label=NativeBatchNormBackward0]
	2022054424352 -> 2022054424208
	2022054424352 [label=ConvolutionBackward0]
	2022054424544 -> 2022054424352
	2022054424544 [label=ReluBackward0]
	2022054424688 -> 2022054424544
	2022054424688 [label=NativeBatchNormBackward0]
	2022054424784 -> 2022054424688
	2022054424784 [label=ConvolutionBackward0]
	2022054424976 -> 2022054424784
	2022054424976 [label=SqueezeBackward1]
	2022054425120 -> 2022054424976
	2022054425120 [label=AvgPool2DBackward0]
	2022032299856 -> 2022054425120
	2022032299856 [label=UnsqueezeBackward0]
	2022054425264 -> 2022032299856
	2022054425264 [label=ReluBackward0]
	2022054425312 -> 2022054425264
	2022054425312 [label=NativeBatchNormBackward0]
	2022054425456 -> 2022054425312
	2022054425456 [label=ConvolutionBackward0]
	2022054425744 -> 2022054425456
	2022037972352 [label="conv1.weight
 (2, 1, 3)" fillcolor=lightblue]
	2022037972352 -> 2022054425744
	2022054425744 [label=AccumulateGrad]
	2022054425408 -> 2022054425312
	2021540140272 [label="bn1.weight
 (2)" fillcolor=lightblue]
	2021540140272 -> 2022054425408
	2022054425408 [label=AccumulateGrad]
	2022054425552 -> 2022054425312
	2021540140192 [label="bn1.bias
 (2)" fillcolor=lightblue]
	2021540140192 -> 2022054425552
	2022054425552 [label=AccumulateGrad]
	2022054424928 -> 2022054424784
	2021540204608 [label="layer1.0.conv1.weight
 (2, 2, 3)" fillcolor=lightblue]
	2021540204608 -> 2022054424928
	2022054424928 [label=AccumulateGrad]
	2022054424736 -> 2022054424688
	2021540204528 [label="layer1.0.bn1.weight
 (2)" fillcolor=lightblue]
	2021540204528 -> 2022054424736
	2022054424736 [label=AccumulateGrad]
	2022054424592 -> 2022054424688
	2021540211168 [label="layer1.0.bn1.bias
 (2)" fillcolor=lightblue]
	2021540211168 -> 2022054424592
	2022054424592 [label=AccumulateGrad]
	2022054424496 -> 2022054424352
	2021540210928 [label="layer1.0.conv2.weight
 (2, 2, 3)" fillcolor=lightblue]
	2021540210928 -> 2022054424496
	2022054424496 [label=AccumulateGrad]
	2022054424304 -> 2022054424208
	2021540204288 [label="layer1.0.bn2.weight
 (2)" fillcolor=lightblue]
	2021540204288 -> 2022054424304
	2022054424304 [label=AccumulateGrad]
	2022054424256 -> 2022054424208
	2021540204208 [label="layer1.0.bn2.bias
 (2)" fillcolor=lightblue]
	2021540204208 -> 2022054424256
	2022054424256 [label=AccumulateGrad]
	2022054424160 -> 2022054424112
	2022054424160 [label=NativeBatchNormBackward0]
	2022054253792 -> 2022054424160
	2022054253792 [label=ConvolutionBackward0]
	2022054424976 -> 2022054253792
	2022054425216 -> 2022054253792
	2021540146672 [label="layer1.0.downsample.0.weight
 (2, 2, 1)" fillcolor=lightblue]
	2021540146672 -> 2022054425216
	2022054425216 [label=AccumulateGrad]
	2022054424448 -> 2022054424160
	2021540204688 [label="layer1.0.downsample.1.weight
 (2)" fillcolor=lightblue]
	2021540204688 -> 2022054424448
	2022054424448 [label=AccumulateGrad]
	2022054424400 -> 2022054424160
	2021540204848 [label="layer1.0.downsample.1.bias
 (2)" fillcolor=lightblue]
	2021540204848 -> 2022054424400
	2022054424400 [label=AccumulateGrad]
	2022054423920 -> 2022054423776
	2021540203728 [label="layer2.0.conv1.weight
 (4, 2, 3)" fillcolor=lightblue]
	2021540203728 -> 2022054423920
	2022054423920 [label=AccumulateGrad]
	2022054423728 -> 2022054423680
	2021540210368 [label="layer2.0.bn1.weight
 (4)" fillcolor=lightblue]
	2021540210368 -> 2022054423728
	2022054423728 [label=AccumulateGrad]
	2022054423584 -> 2022054423680
	2021540210288 [label="layer2.0.bn1.bias
 (4)" fillcolor=lightblue]
	2021540210288 -> 2022054423584
	2022054423584 [label=AccumulateGrad]
	2022054423488 -> 2022054423344
	2021540216768 [label="layer2.0.conv2.weight
 (4, 4, 3)" fillcolor=lightblue]
	2021540216768 -> 2022054423488
	2022054423488 [label=AccumulateGrad]
	2022054423296 -> 2022054423200
	2021540216688 [label="layer2.0.bn2.weight
 (4)" fillcolor=lightblue]
	2021540216688 -> 2022054423296
	2022054423296 [label=AccumulateGrad]
	2022054423248 -> 2022054423200
	2021540203648 [label="layer2.0.bn2.bias
 (4)" fillcolor=lightblue]
	2021540203648 -> 2022054423248
	2022054423248 [label=AccumulateGrad]
	2022054423152 -> 2022054423104
	2022054423152 [label=NativeBatchNormBackward0]
	2022054423824 -> 2022054423152
	2022054423824 [label=ConvolutionBackward0]
	2022054423968 -> 2022054423824
	2022054423872 -> 2022054423824
	2021540210688 [label="layer2.0.downsample.0.weight
 (4, 2, 1)" fillcolor=lightblue]
	2021540210688 -> 2022054423872
	2022054423872 [label=AccumulateGrad]
	2022054424832 -> 2022054423152
	2021540210608 [label="layer2.0.downsample.1.weight
 (4)" fillcolor=lightblue]
	2021540210608 -> 2022054424832
	2022054424832 [label=AccumulateGrad]
	2022054423392 -> 2022054423152
	2021540203968 [label="layer2.0.downsample.1.bias
 (4)" fillcolor=lightblue]
	2021540203968 -> 2022054423392
	2022054423392 [label=AccumulateGrad]
	2022054422912 -> 2022054422768
	2021540209728 [label="layer3.0.conv1.weight
 (8, 4, 3)" fillcolor=lightblue]
	2021540209728 -> 2022054422912
	2022054422912 [label=AccumulateGrad]
	2022054422720 -> 2022054422672
	2021540209648 [label="layer3.0.bn1.weight
 (8)" fillcolor=lightblue]
	2021540209648 -> 2022054422720
	2022054422720 [label=AccumulateGrad]
	2022054422576 -> 2022054422672
	2021540216448 [label="layer3.0.bn1.bias
 (8)" fillcolor=lightblue]
	2021540216448 -> 2022054422576
	2022054422576 [label=AccumulateGrad]
	2022054422480 -> 2022054422336
	2021540209488 [label="layer3.0.conv2.weight
 (8, 8, 3)" fillcolor=lightblue]
	2021540209488 -> 2022054422480
	2022054422480 [label=AccumulateGrad]
	2022054422288 -> 2022054422192
	2021540216288 [label="layer3.0.bn2.weight
 (8)" fillcolor=lightblue]
	2021540216288 -> 2022054422288
	2022054422288 [label=AccumulateGrad]
	2022054422240 -> 2022054422192
	2021540216208 [label="layer3.0.bn2.bias
 (8)" fillcolor=lightblue]
	2021540216208 -> 2022054422240
	2022054422240 [label=AccumulateGrad]
	2022054422144 -> 2022054422096
	2022054422144 [label=NativeBatchNormBackward0]
	2022054422816 -> 2022054422144
	2022054422816 [label=ConvolutionBackward0]
	2022054422960 -> 2022054422816
	2022054422864 -> 2022054422816
	2021540203248 [label="layer3.0.downsample.0.weight
 (8, 4, 1)" fillcolor=lightblue]
	2021540203248 -> 2022054422864
	2022054422864 [label=AccumulateGrad]
	2022054423440 -> 2022054422144
	2021540209888 [label="layer3.0.downsample.1.weight
 (8)" fillcolor=lightblue]
	2021540209888 -> 2022054423440
	2022054423440 [label=AccumulateGrad]
	2022054422384 -> 2022054422144
	2021540209808 [label="layer3.0.downsample.1.bias
 (8)" fillcolor=lightblue]
	2021540209808 -> 2022054422384
	2022054422384 [label=AccumulateGrad]
	2022054421472 -> 2022050282080
	2022054421472 [label=TBackward0]
	2022054421616 -> 2022054421472
	2021540209328 [label="fc.weight
 (2, 8)" fillcolor=lightblue]
	2021540209328 -> 2022054421616
	2022054421616 [label=AccumulateGrad]
	2022050282080 -> 2022041999696
}
